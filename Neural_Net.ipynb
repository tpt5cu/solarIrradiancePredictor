{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import some sample data\n",
    "# Load data\n",
    "#2017 psm data\n",
    "# Lat/lon: 43.85, -99.5\n",
    "df1_2018 = pd.read_csv(os.path.join(_Testing_Data_Dir,'psm_south_dakota', 'psm_testing_data2018.csv'))\n",
    "df1_psm_2017= pd.read_csv(os.path.join(_Testing_Data_Dir, 'psm_south_dakota', 'psm_testing_data2017.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets try and make a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tuomastalvitie/Documents/GRIP/Diffuse:Direct/solarIrradiencePredictor/Testing_Data\n"
     ]
    }
   ],
   "source": [
    "#Get 2018 Data\n",
    "_Curr_Dir = os.getcwd()\n",
    "_Testing_Data_Dir = os.path.join(_Curr_Dir, 'Testing_Data')\n",
    "print(_Testing_Data_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "So we have all the above variables....Which ones do we think would work best in a NN?\n",
    "\n",
    "Perhaps a seasonality variable?\n",
    "Cloud cover for sure\n",
    "DHI DNI too\n",
    "Pressure\n",
    "Solar Zenith Angle\n",
    "\n",
    "Lets leave the seasonality variable for last\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get training arrays and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_training_arrays(df, input_arry, output_arr):\n",
    "    ghi  = df['GHI'].values\n",
    "    cloud_cover = df['Cloud Cover'].values\n",
    "    hours = df['Hour'].values\n",
    "    minutes = df['Minute'].values\n",
    "    solar_zenith = df['Solar Zenith Angle'].values\n",
    "    pressure = df['Pressure'].values\n",
    "    dhi = df['DHI'].values\n",
    "    assert len(pressure)==len(solar_zenith)==len(minutes)==len(hours)==len(cloud_cover)==len(ghi)==8760, \"len of input array not 8760\"\n",
    "    ar = np.array([ghi, cloud_cover, hours, minutes, solar_zenith, pressure]).T\n",
    "    input_arry = np.concatenate((input_arry, ar))\n",
    "    output_arr = np.concatenate((output_arr, np.array(dhi).T))\n",
    "    return input_arry, output_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[[0.0000e+00 0.0000e+00 0.0000e+00 3.0000e+01 1.1318e+02 1.0190e+03]\n",
      " [0.0000e+00 0.0000e+00 1.0000e+00 3.0000e+01 1.2631e+02 1.0190e+03]\n",
      " [0.0000e+00 0.0000e+00 2.0000e+00 3.0000e+01 1.3965e+02 1.0190e+03]\n",
      " ...\n",
      " [1.9900e+02 1.0000e-01 2.1000e+01 3.0000e+01 7.3700e+01 9.4300e+02]\n",
      " [1.2200e+02 6.0000e-02 2.2000e+01 3.0000e+01 7.8720e+01 9.4300e+02]\n",
      " [3.6000e+01 2.9000e-01 2.3000e+01 3.0000e+01 8.5460e+01 9.4300e+02]]\n",
      "(429240, 6)\n",
      "[ 0.  0.  0. ... 96. 68. 28.]\n",
      "(429240,)\n",
      "[  0.   0.   0. ... 199. 122.  36.]\n"
     ]
    }
   ],
   "source": [
    "input_size = 6\n",
    "input_arry = np.array([], dtype=np.float64).reshape(0,input_size)\n",
    "output_arry = np.array([], dtype=np.float64)\n",
    "print(input_arry)\n",
    "print(output_arry)\n",
    "from glob import glob\n",
    "for path in glob(_Testing_Data_Dir+'/*'):\n",
    "    for file in glob(path+'/psm_'+'*'):\n",
    "        df = pd.read_csv(file)\n",
    "        input_arry, output_arry = combine_training_arrays(df, input_arry, output_arry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429240\n"
     ]
    }
   ],
   "source": [
    "#sanity check, make sure 8760*number of files we look at == 429240\n",
    "count = 0\n",
    "for path in glob(_Testing_Data_Dir+'/*'):\n",
    "    for file in glob(path+'/psm_'+'*'):\n",
    "        count+=1\n",
    "print(count*8760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second sanity check\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(2, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429240/429240 [==============================] - 405s 943us/step - loss: 13807.2021 - mae: 65.1752\n",
      "Epoch 2/10\n",
      "429240/429240 [==============================] - 687s 2ms/step - loss: 13807.0283 - mae: 65.1748\n",
      "Epoch 3/10\n",
      "429240/429240 [==============================] - 372s 867us/step - loss: 13806.9580 - mae: 65.1752\n",
      "Epoch 4/10\n",
      "429240/429240 [==============================] - 335s 780us/step - loss: 13806.9004 - mae: 65.1732\n",
      "Epoch 5/10\n",
      "429240/429240 [==============================] - 364s 847us/step - loss: 13807.0996 - mae: 65.1749\n",
      "Epoch 6/10\n",
      "429240/429240 [==============================] - 337s 785us/step - loss: 13806.9922 - mae: 65.1751\n",
      "Epoch 7/10\n",
      "429240/429240 [==============================] - 334s 778us/step - loss: 13806.9922 - mae: 65.1742\n",
      "Epoch 8/10\n",
      "429240/429240 [==============================] - 346s 807us/step - loss: 13807.0605 - mae: 65.1757\n",
      "Epoch 9/10\n",
      "429240/429240 [==============================] - 334s 779us/step - loss: 13807.0010 - mae: 65.1741\n",
      "Epoch 10/10\n",
      "429240/429240 [==============================] - 334s 777us/step - loss: 13806.9961 - mae: 65.1760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13da32410>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and train\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.fit(input_arry, output_arry, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13414/13414 [==============================] - 13s 962us/step - loss: 13805.1934 - mae: 65.3293\n",
      "Epoch 2/10\n",
      "13414/13414 [==============================] - 11s 786us/step - loss: 13804.4980 - mae: 65.3272\n",
      "Epoch 3/10\n",
      "13414/13414 [==============================] - 12s 875us/step - loss: 13804.4795 - mae: 65.3275\n",
      "Epoch 4/10\n",
      "13414/13414 [==============================] - 11s 784us/step - loss: 13804.4746 - mae: 65.3274\n",
      "Epoch 5/10\n",
      "13414/13414 [==============================] - 11s 798us/step - loss: 13804.4717 - mae: 65.3273 0s - loss: 13793.324\n",
      "Epoch 6/10\n",
      "13414/13414 [==============================] - 11s 784us/step - loss: 13804.4629 - mae: 65.3274\n",
      "Epoch 7/10\n",
      "13414/13414 [==============================] - 11s 783us/step - loss: 13804.4619 - mae: 65.3276s - loss: 13795.458 - ETA: 0s - loss: 13808.3164 - mae: 65. - ETA: 0s -\n",
      "Epoch 8/10\n",
      "13414/13414 [==============================] - 11s 825us/step - loss: 13804.5146 - mae: 65.3272\n",
      "Epoch 9/10\n",
      "13414/13414 [==============================] - 11s 802us/step - loss: 13804.4609 - mae: 65.3272\n",
      "Epoch 10/10\n",
      "13414/13414 [==============================] - 11s 799us/step - loss: 13804.5381 - mae: 65.3272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13eeb8150>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and train\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.fit(input_arry, output_arry, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(20, activation=\"relu\"))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13414/13414 [==============================] - 13s 959us/step - loss: 13804.7383 - mae: 65.3275\n",
      "Epoch 2/10\n",
      "13414/13414 [==============================] - 13s 985us/step - loss: 13804.5010 - mae: 65.3274\n",
      "Epoch 3/10\n",
      "13414/13414 [==============================] - 13s 936us/step - loss: 13804.4893 - mae: 65.3274\n",
      "Epoch 4/10\n",
      "13414/13414 [==============================] - 12s 919us/step - loss: 13804.4834 - mae: 65.3272\n",
      "Epoch 5/10\n",
      "13414/13414 [==============================] - 12s 913us/step - loss: 13804.4746 - mae: 65.3274\n",
      "Epoch 6/10\n",
      "13414/13414 [==============================] - 13s 940us/step - loss: 13804.5146 - mae: 65.3273- ETA\n",
      "Epoch 7/10\n",
      "13414/13414 [==============================] - 13s 957us/step - loss: 13804.4961 - mae: 65.3274\n",
      "Epoch 8/10\n",
      "13414/13414 [==============================] - 13s 954us/step - loss: 13804.4590 - mae: 65.3276\n",
      "Epoch 9/10\n",
      "13414/13414 [==============================] - 13s 963us/step - loss: 13804.5479 - mae: 65.3273\n",
      "Epoch 10/10\n",
      "13414/13414 [==============================] - 13s 963us/step - loss: 13804.4404 - mae: 65.3272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13f9c1d90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and train\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.fit(input_arry, output_arry, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(20, activation=\"relu\"))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26828/26828 [==============================] - 24s 909us/step - loss: 13804.5312 - mae: 65.3274s - loss: 13795.0850 - ma\n",
      "Epoch 2/10\n",
      "26828/26828 [==============================] - 23s 848us/step - loss: 13804.4873 - mae: 65.3276 17s - lo - E\n",
      "Epoch 3/10\n",
      "26828/26828 [==============================] - 25s 929us/step - loss: 13804.5225 - mae: 65.3272 21s - loss: 13935.7852 - ma - ETA: 21s - ETA: 19s - loss: 13805.4932 - mae: - ETA - ETA: 18s - loss: 13811.4014 - mae - ETA: 18s - loss: 13865. - ETA: 17s - loss: 13834.8486 - - ETA: 16s - loss: 13829.2031 - mae: 6 - ETA: 15s - loss: - ETA: 14s - loss: 13793 - - ETA: 11s - loss: 13836.7490 - mae: 65.432 - ETA: 11s - loss: 13836.5537 - mae: 65 - ETA: 10s - loss: 13827.7812 - mae: 6 - ETA - ETA: 7s - loss: 13837.4785 - mae: 65.43 - ETA: 7s - l - ETA: 6s -\n",
      "Epoch 4/10\n",
      "26828/26828 [==============================] - 25s 930us/step - loss: 13804.4805 - mae: 65.3271s - loss: 13801.2383 - mae:\n",
      "Epoch 5/10\n",
      "26828/26828 [==============================] - 24s 879us/step - loss: 13804.4961 - mae: 65.3275s - loss: 13810.9131 - ma - ETA: 0s - loss: 13807.1\n",
      "Epoch 6/10\n",
      "26828/26828 [==============================] - 23s 867us/step - loss: 13804.4951 - mae: 65.3274 21 - ETA: 19s - loss: 13894.4990 - ETA: 18s - loss: 13906.9658 - ma - ETA: 1 - ETA: 0s - los\n",
      "Epoch 7/10\n",
      "26828/26828 [==============================] - 29s 1ms/step - loss: 13804.4658 - mae: 65.3275A: 14s - loss: 13813.4287  - ETA: 13s - loss: 13821.9189 - mae: 65 - ETA: 13s - loss: 13817.0283 -  - ETA: 12s - loss: 13823.5605 - ma - ETA: 11s - loss: 13814.6152 - ma - ETA: 0s - loss: 13794.4492 - ma - ETA: 0s - loss: 13804\n",
      "Epoch 8/10\n",
      "26828/26828 [==============================] - 23s 869us/step - loss: 13804.5088 - mae: 65.3276 21s - loss: 13784.7275 -  - ETA: 18s - loss: 13677.4785 - mae:  - ETA: 18s - loss: 13735.6426 - mae: 64.85 - ETA: 18s - loss: 137\n",
      "Epoch 9/10\n",
      "26828/26828 [==============================] - 23s 859us/step - loss: 13804.5020 - mae: 65.3272 19s - loss: 13857.3389 - mae: 65.6 - ETA: 19s - loss: 13828.5039  - ETA: 16s - loss: 13788.2676  - ETA: 15s - loss: 13821\n",
      "Epoch 10/10\n",
      "26828/26828 [==============================] - 23s 858us/step - loss: 13804.4824 - mae: 65.3277ETA: 2s - loss: - ETA: 2s - loss: 13829.227 - ETA: 0s - los\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1408539d0>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and train\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.fit(input_arry, output_arry, epochs=10, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(3, activation=\"relu\"))\n",
    "model.add(layers.Dense(5, activation=\"relu\"))\n",
    "model.add(layers.Dense(10, activation=\"relu\"))\n",
    "model.add(layers.Dense(20, activation=\"relu\"))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(3, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "429240/429240 [==============================] - 341s 794us/step - loss: 13936.9922 - mae: 65.3186 - los -\n",
      "Epoch 2/10\n",
      "429240/429240 [==============================] - 535s 1ms/step - loss: 13937.2207 - mae: 65.3185\n",
      "Epoch 3/10\n",
      "429240/429240 [==============================] - 701s 2ms/step - loss: 13936.9053 - mae: 65.3178\n",
      "Epoch 4/10\n",
      "429240/429240 [==============================] - 825s 2ms/step - loss: 13937.1094 - mae: 65.31850s - loss: 13937.1445 - mae:\n",
      "Epoch 5/10\n",
      "429240/429240 [==============================] - 792s 2ms/step - loss: 13937.1094 - mae: 65.3181\n",
      "Epoch 6/10\n",
      "429240/429240 [==============================] - 647s 2ms/step - loss: 13937.1387 - mae: 65.31760s - loss: 13936.0713 - ma\n",
      "Epoch 7/10\n",
      "429240/429240 [==============================] - 708s 2ms/step - loss: 13937.1484 - mae: 65.3174\n",
      "Epoch 8/10\n",
      "429240/429240 [==============================] - 428s 998us/step - loss: 13937.0996 - mae: 65.3178\n",
      "Epoch 9/10\n",
      "429240/429240 [==============================] - 395s 921us/step - loss: 13936.9062 - mae: 65.3169\n",
      "Epoch 10/10\n",
      "429240/429240 [==============================] - 385s 897us/step - loss: 13937.1875 - mae: 65.3191\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1424c6350>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Compile and train\n",
    "model.compile(optimizer='adam', \n",
    "              loss='mse',\n",
    "              metrics=['mae'])\n",
    "model.fit(input_arry, output_arry, epochs=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
